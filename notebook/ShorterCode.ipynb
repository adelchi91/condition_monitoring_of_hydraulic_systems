{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae2c9f78-771d-47e1-8a85-e02d58b18849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.transformers import RelevantFeatureAugmenter\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate, TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83aa1faa-bc71-46ac-8570-32117f85265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data():\n",
    "    # Read each file into a DataFrame\n",
    "    df_PS2 = pd.read_csv(\"../data_subset/PS2.txt\", sep=\"\\t\", header=None)\n",
    "    df_FS1 = pd.read_csv(\"../data_subset/FS1.txt\", sep=\"\\t\", header=None)\n",
    "    df_profile = pd.read_csv(\"../data_subset/profile.txt\", sep=\"\\t\", header=None)\n",
    "    \n",
    "    df_profile.columns = ['cooler_condition_%', 'valve_condition_%', 'internal_pump_leakage',\n",
    "                          'hydraulic_accumulator_bar', 'stable_flag' ]\n",
    "    return df_PS2, df_FS1, df_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9793bdf-da1e-403e-9675-ba379b0c3d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_dataframes(df_PS2, df_FS1):\n",
    "    # Transpose the FS1 DataFrame to have time series as rows\n",
    "    df_FS1_transposed = df_FS1.T\n",
    "    \n",
    "    # Create a datetime index for the transposed FS1 DataFrame\n",
    "    fs1_time_index = pd.date_range(start='2024-01-01', periods=len(df_FS1_transposed), freq='10ms')\n",
    "    df_FS1_transposed.index = fs1_time_index\n",
    "    \n",
    "    # Resample FS1 to match the frequency of PS2 (from 10 Hz to 100 Hz)\n",
    "    df_FS1_resampled_transposed = df_FS1_transposed.resample('10ms').interpolate()\n",
    "    \n",
    "    # Transpose back to the original format\n",
    "    df_FS1_resampled = df_FS1_resampled_transposed.T\n",
    "    \n",
    "    # Transpose the PS2 DataFrame to have time series as rows\n",
    "    df_PS2_transposed = df_PS2.T\n",
    "    \n",
    "    # Create a datetime index for the transposed PS2 DataFrame\n",
    "    ps2_time_index = pd.date_range(start='2024-01-01', periods=len(df_PS2_transposed), freq='10ms')\n",
    "    df_PS2_transposed.index = ps2_time_index\n",
    "    \n",
    "    # Resample PS2 to match the frequency of FS1 (from 100 Hz to 10 Hz)\n",
    "    df_PS2_resampled_transposed = df_PS2_transposed.resample('100ms').interpolate()\n",
    "    \n",
    "    # Transpose back to the original format\n",
    "    df_PS2_resampled = df_PS2_resampled_transposed.T\n",
    "    return df_PS2_resampled, df_FS1_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37c7def2-b8ff-499c-93a0-16ed475f7cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangling_for_tsfresh(df):\n",
    "    # Reset index to convert the timestamps to a regular column\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Melt the DataFrame to create the 'id', 'timestamp', and 'value' columns\n",
    "    df_melted = pd.melt(df, id_vars=['index'], var_name='timestamp', value_name='value')\n",
    "    \n",
    "    # Rename the columns\n",
    "    df_melted.columns = ['id', 'timestamp', 'value']\n",
    "    \n",
    "    # Sort by 'id' for better clarity\n",
    "    df_melted = df_melted.sort_values(by='id').reset_index(drop=True)\n",
    "    return df_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac6c91-8a4b-4a63-971d-3a37b7ffee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to your data\n",
    "df[\"valve_condition_%\"].iloc[:2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3254b4f8-6d3f-48fc-8d81-73474d6288fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_(df, nb_cycles=2000):\n",
    "    X = df.drop(columns = [\"valve_condition_%\"]).copy()\n",
    "    y = df[\"valve_condition_%\"].copy()\n",
    "    X_train_test, X_val = X.iloc[:nb_cycles], X.iloc[nb_cycles:]\n",
    "    y_train_test, y_val = y.iloc[:nb_cycles], y.iloc[nb_cycles:]\n",
    "    return X_train_test, X_val, y_train_test, y_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38d8f71d-429f-473d-bb06-0af3a6901976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_creation(X_train, y_train):\n",
    "    # Define the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('augmenter', RelevantFeatureAugmenter(column_id='id', column_sort='timestamp', n_jobs=3)),\n",
    "        ('classifier', XGBClassifier(\n",
    "            # random_state=42,\n",
    "            # n_estimators=100,  # Number of trees in the ensemble\n",
    "            # max_depth=2,  # Maximum depth of each tree\n",
    "            # learning_rate=0.1,  # Step size shrinkage used in update to prevent overfitting\n",
    "            # min_child_weight=1,  # Minimum sum of instance weight (hessian) needed in a child\n",
    "            # subsample=0.8,  # Subsample ratio of the training instance\n",
    "            # colsample_bytree=0.8,  # Subsample ratio of columns when constructing each tree\n",
    "            # reg_alpha=0,  # L1 regularization term on weights\n",
    "            # reg_lambda=1,  # L2 regularization term on weights\n",
    "            # gamma=0,  # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "        ))  # XGBoost classifier\n",
    "    ])\n",
    "    \n",
    "    # Define the evaluation metrics\n",
    "    scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall',\n",
    "        'f1': 'f1',\n",
    "        'roc_auc': 'roc_auc'\n",
    "    }\n",
    "    pipeline.set_params(augmenter__timeseries_container=X_train)\n",
    "    # Perform time series cross-validation\n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, cv=TimeSeriesSplit(n_splits=5), scoring=scoring)\n",
    "    \n",
    "    # Compute relevant metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Accuracy': cv_results['test_accuracy'],\n",
    "        'Precision': cv_results['test_precision'],\n",
    "        'Recall': cv_results['test_recall'],\n",
    "        'F1': cv_results['test_f1'],\n",
    "        'AUC': cv_results['test_roc_auc']\n",
    "    })\n",
    "    return pipeline, cv_results, metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aad29a0f-9801-42ee-91cf-477f9a2a11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_score(pipeline, X_train, y_train, X_test, y_test):\n",
    "    pipeline.set_params(augmenter__timeseries_container=X_train)\n",
    "    # Fit the pipeline to the training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the target variable on the test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    # Create a DataFrame to store the metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Accuracy': [accuracy],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1': [f1],\n",
    "        'AUC': [roc_auc]\n",
    "    })\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd4d3436-776a-4b60-82cc-bba1540adec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "# loading data\n",
    "df_PS2, df_FS1, df_profile = loading_data()\n",
    "# resampling data with same frequency \n",
    "df_PS2_resampled, df_FS1_resampled = resample_dataframes(df_PS2, df_FS1)\n",
    "# data wrangling - for tsfresh \n",
    "df_PS2_melted = wrangling_for_tsfresh(df_PS2_resampled)\n",
    "df_FS1_melted = wrangling_for_tsfresh(df_FS1_resampled) #[lambda x: x.id==0]\n",
    "# full dataframe \n",
    "df_full = pd.concat([df_FS1_melted.rename(columns={'value': 'fs1'}),\n",
    "                     df_PS2_melted.rename(columns={'value': 'ps2'})['ps2']], axis=1)\n",
    "# adding target variable to dataframe \n",
    "df_to_model = pd.concat([df_full, df_profile[\"valve_condition_%\"]], axis=1)\n",
    "# Changing target variable into a binary variable 100=1, the rest=0\n",
    "df_to_model['valve_condition_%'] = np.where(df_to_model['valve_condition_%'] == 100, 1, 0)\n",
    "# train-test split\n",
    "X_train_test, X_val, y_train_test, y_val = train_test_split_(df_to_model, nb_cycles=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ac4e00a-34a1-40ce-a594-60d37347d651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>fs1</th>\n",
       "      <th>ps2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>8.990</td>\n",
       "      <td>125.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-01-01 00:00:00.550000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-01-01 00:00:03.430000</td>\n",
       "      <td>7.773</td>\n",
       "      <td>140.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-01-01 00:00:03.440000</td>\n",
       "      <td>7.968</td>\n",
       "      <td>140.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-01-01 00:00:00.540000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322995</th>\n",
       "      <td>2204</td>\n",
       "      <td>2024-01-01 00:00:03.970000</td>\n",
       "      <td>8.131</td>\n",
       "      <td>130.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322996</th>\n",
       "      <td>2204</td>\n",
       "      <td>2024-01-01 00:00:03.960000</td>\n",
       "      <td>7.908</td>\n",
       "      <td>130.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322997</th>\n",
       "      <td>2204</td>\n",
       "      <td>2024-01-01 00:00:03.950000</td>\n",
       "      <td>8.288</td>\n",
       "      <td>130.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322998</th>\n",
       "      <td>2204</td>\n",
       "      <td>2024-01-01 00:00:03.930000</td>\n",
       "      <td>9.444</td>\n",
       "      <td>131.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322999</th>\n",
       "      <td>2204</td>\n",
       "      <td>2024-01-01 00:00:05.990000</td>\n",
       "      <td>7.774</td>\n",
       "      <td>125.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1323000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                   timestamp    fs1     ps2\n",
       "0           0         2024-01-01 00:00:00  8.990  125.50\n",
       "1           0  2024-01-01 00:00:00.550000  0.000    0.00\n",
       "2           0  2024-01-01 00:00:03.430000  7.773  140.41\n",
       "3           0  2024-01-01 00:00:03.440000  7.968  140.60\n",
       "4           0  2024-01-01 00:00:00.540000  0.001    0.00\n",
       "...       ...                         ...    ...     ...\n",
       "1322995  2204  2024-01-01 00:00:03.970000  8.131  130.86\n",
       "1322996  2204  2024-01-01 00:00:03.960000  7.908  130.93\n",
       "1322997  2204  2024-01-01 00:00:03.950000  8.288  130.65\n",
       "1322998  2204  2024-01-01 00:00:03.930000  9.444  131.94\n",
       "1322999  2204  2024-01-01 00:00:05.990000  7.774  125.48\n",
       "\n",
       "[1323000 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d495f-59ba-40bb-a6b2-ecd448e2dd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction:  20%|███████████████▊                                                               | 3/15 [00:13<00:37,  3.11s/it]"
     ]
    }
   ],
   "source": [
    "df_temp = df_profile.copy()\n",
    "df_temp[\"valve_condition_%\"] = np.where(df_profile[\"valve_condition_%\"]== 100, 1, 0)\n",
    "df = df_full.copy()\n",
    "nb_cycles=100\n",
    "\n",
    "X = df.copy()\n",
    "y = df_temp[\"valve_condition_%\"].copy()\n",
    "X_train_test, X_val = X.iloc[:nb_cycles], X.iloc[nb_cycles:]\n",
    "# Define the pipeline with only the first step\n",
    "pipeline_first_step = Pipeline([\n",
    "    ('augmenter', RelevantFeatureAugmenter(column_id='id', column_sort='timestamp', n_jobs=3))\n",
    "])\n",
    "\n",
    "# Set the timeseries container\n",
    "pipeline_first_step.set_params(augmenter__timeseries_container=df)\n",
    "# Fit the pipeline to your data\n",
    "pipeline_first_step.fit(X_train_test, y.iloc[:nb_cycles])\n",
    "# Transform the data using only the first step\n",
    "X_transformed = pipeline_first_step.transform(X_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a99c10-e860-4145-aaae-3a0786e1c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f20de1c-ebd0-4c41-b26b-256302a68fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation\n",
    "print('CROSS-VALIDATION STARTED')\n",
    "pipeline, cv_results, cv_metrics_df = pipeline_creation(X_train_test, y_train_test)\n",
    "cv_metrics_df.to_csv(\"../data/cv_metrics_df.csv\")\n",
    "# validation performance \n",
    "print('VALIDATION STARTED')\n",
    "val_metrics_df = validation_score(pipeline, X_train_test, y_train_test, X_val, y_val)\n",
    "val_metrics_df.to_csv(\"../data/val_metrics_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ecd621-8f7e-4117-936f-e46d6506e9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
